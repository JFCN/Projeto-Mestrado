"""
Sistema de IA para Predi√ß√£o de Sobreviv√™ncia em Tuberculose Infantil
COM SUBSTITUI√á√ÉO INTELIGENTE DE FEATURES

Fluxo:
1. Sele√ß√£o de Features com Substitui√ß√£o Inteligente
2. An√°lise Temporal Cl√≠nica
3. Detec√ß√£o de Data Leakage
4. Treinamento com TabPFN + Meta-Models
5. Gera√ß√£o de Relat√≥rios

Autor: Janduhy Finizola da Cunha Neto
"""

import os
import sys
import time
import io
import locale
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, Tuple, List
import traceback
import json


def ensure_feature_selector_compatibility(feature_selector):
    """
    Garante que o feature_selector tenha os m√©todos necess√°rios
    """
    if feature_selector is None:
        return None

    if not hasattr(feature_selector, 'transform'):
        logger.warning("‚ö†Ô∏è Feature selector n√£o tem m√©todo transform. Adicionando...")

        # Adiciona os m√©todos necess√°rios dinamicamente
        def fit_method(self, X, y=None):
            if hasattr(self, 'selected_features') and self.selected_features:
                self.feature_names_ = self.selected_features
            else:
                self.feature_names_ = list(X.columns) if hasattr(X, 'columns') else [f'feature_{i}' for i in
                                                                                     range(X.shape[1])]
            return self

        def transform_method(self, X):
            if not hasattr(self, 'feature_names_'):
                return X

            if hasattr(X, 'columns'):
                available_features = [f for f in self.feature_names_ if f in X.columns]
                return X[available_features]
            else:
                return X

        def fit_transform_method(self, X, y=None):
            return self.fit(X, y).transform(X)

        # Adiciona os m√©todos √† inst√¢ncia
        feature_selector.fit = fit_method.__get__(feature_selector, type(feature_selector))
        feature_selector.transform = transform_method.__get__(feature_selector, type(feature_selector))
        feature_selector.fit_transform = fit_transform_method.__get__(feature_selector, type(feature_selector))

        logger.info("‚úÖ M√©todos de compatibilidade adicionados ao feature_selector")

    return feature_selector

def apply_categorical_mapping_patch():
    """
    Aplica corre√ß√£o imediata para mapeamento categ√≥rico
    """
    import pandas as pd
    import numpy as np
    import logging
    import types

    logger = logging.getLogger('FeatureSelector')

    def _create_score_comorbidades_patched(self):
        """SCORE_COMORBIDADES com mapeamento categ√≥rico"""
        try:
            comorbidades = ['AGRAVAIDS', 'AGRAVALCOO', 'AGRAVDIABE', 'AGRAVDOENC',
                            'AGRAVDROGA', 'AGRAVTABAC', 'AGRAVOUTRA']

            logger.info("üîß Criando SCORE_COMORBIDADES com mapeamento categ√≥rico ...")

            # Mapeamento robusto para valores categ√≥ricos
            mapping_values = {
                'SIM': 1, 'sim': 1, 'Sim': 1,
                'N√ÉO': 0, 'n√£o': 0, 'N√£o': 0, 'NAO': 0, 'nao': 0, 'Nao': 0,
                'IGNORADO': 0, 'ignorado': 0, 'Ignorado': 0,
                '1': 1, '2': 0, '9': 0,
                1: 1, 2: 0, 9: 0,
                np.nan: 0, None: 0, '': 0
            }

            score = pd.Series(0, index=self.df.index)
            valid_comorbidades = []

            for col in comorbidades:
                if col not in self.df.columns:
                    continue

                # Aplicar mapeamento categ√≥rico
                col_data = self.df[col].copy()
                col_mapped = col_data.map(mapping_values).fillna(0).astype(int)

                positive_cases = (col_mapped == 1).sum()
                score += col_mapped
                valid_comorbidades.append(col)

                logger.info(f"   ‚úÖ {col}: {positive_cases} casos positivos de {len(col_data)}")

            if not valid_comorbidades:
                logger.error("‚ùå Nenhuma coluna de comorbidade v√°lida encontrada")
                return False

            # Criar a feature derivada
            self.df['SCORE_COMORBIDADES'] = score
            self.derived_features.append('SCORE_COMORBIDADES')

            # Configurar substitui√ß√£o
            self._register_replacement('SCORE_COMORBIDADES', valid_comorbidades, 'high', 'full')

            # Log do resultado
            score_stats = score.value_counts().sort_index()
            total_cases = len(self.df)

            logger.info("‚úÖ SCORE_COMORBIDADES criado com sucesso!")
            logger.info(f"   üìä Componentes: {len(valid_comorbidades)} comorbidades")
            logger.info(f"   üìà Distribui√ß√£o:")
            for score_val, count in score_stats.items():
                percentage = (count / total_cases) * 100
                logger.info(f"      Score {score_val}: {count} casos ({percentage:.1f}%)")

            if self.replacement_config['log_replacements']:
                logger.info(f"   üîÑ Substituir√°: {valid_comorbidades}")

            return True

        except Exception as e:
            logger.error(f"‚ùå Erro ao criar SCORE_COMORBIDADES: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False

    def _create_risco_social_patched(self):
        """RISCO_SOCIAL com mapeamento categ√≥rico """
        try:
            pop_especiais = ['POP_LIBER', 'POP_RUA', 'POP_IMIG']

            logger.info("üîß Criando RISCO_SOCIAL com mapeamento categ√≥rico...")

            mapping_values = {
                'SIM': 1, 'sim': 1, 'Sim': 1,
                'N√ÉO': 0, 'n√£o': 0, 'N√£o': 0, 'NAO': 0, 'nao': 0, 'Nao': 0,
                'IGNORADO': 0, 'ignorado': 0, 'Ignorado': 0,
                '1': 1, '2': 0, '9': 0,
                1: 1, 2: 0, 9: 0,
                np.nan: 0, None: 0, '': 0
            }

            risco = pd.Series(0, index=self.df.index)
            valid_pops = []

            for col in pop_especiais:
                if col not in self.df.columns:
                    continue

                col_data = self.df[col].copy()
                col_mapped = col_data.map(mapping_values).fillna(0).astype(int)

                positive_cases = (col_mapped == 1).sum()
                risco += col_mapped
                valid_pops.append(col)

                logger.info(f"   ‚úÖ {col}: {positive_cases} casos positivos")

            if not valid_pops:
                logger.warning("‚ö†Ô∏è Nenhuma coluna de popula√ß√£o especial encontrada")
                return False

            self.df['RISCO_SOCIAL'] = risco
            self.derived_features.append('RISCO_SOCIAL')
            self._register_replacement('RISCO_SOCIAL', valid_pops, 'high', 'full')

            risco_stats = risco.value_counts().sort_index()
            total_cases = len(self.df)

            logger.info("‚úÖ RISCO_SOCIAL criado com sucesso!")
            logger.info(f"   üìä Componentes: {len(valid_pops)} popula√ß√µes especiais")
            for risco_val, count in risco_stats.items():
                percentage = (count / total_cases) * 100
                logger.info(f"      Risco {risco_val}: {count} casos ({percentage:.1f}%)")

            return True

        except Exception as e:
            logger.error(f"‚ùå Erro ao criar RISCO_SOCIAL: {e}")
            return False

    def _create_caso_complexo_patched(self):
        """CASO_COMPLEXO com mapeamento categ√≥rico """
        try:
            logger.info("üîß Criando CASO_COMPLEXO com mapeamento categ√≥rico ...")

            complexidade = []
            mapping_values = {
                'SIM': 1, 'sim': 1, 'Sim': 1,
                'N√ÉO': 0, 'n√£o': 0, 'N√£o': 0, 'NAO': 0, 'nao': 0, 'Nao': 0,
                'IGNORADO': 0, 'ignorado': 0, 'Ignorado': 0,
                '1': 1, '2': 0, '9': 0,
                1: 1, 2: 0, 9: 0,
                np.nan: 0, None: 0, '': 0
            }

            # Forma cl√≠nica extrapulmonar
            if 'FORMA' in self.df.columns:
                forma_data = self.df['FORMA'].astype(str).str.strip().str.lower()
                formas_complexas = forma_data.isin([
                    'extrapulmonar', 'extra-pulmonar', 'extra pulmonar',
                    'pulmonar + extrapulmonar', 'pulmonar+extrapulmonar',
                    'pulmonar e extrapulmonar', '3'
                ])
                complexidade.append(formas_complexas)
                logger.info(f"   ‚úÖ FORMA: {formas_complexas.sum()} casos extrapulmonares")

            # HIV positivo
            if 'HIV' in self.df.columns:
                hiv_data = self.df['HIV']
                if hiv_data.dtype == 'object':
                    hiv_mapped = hiv_data.map(mapping_values).fillna(0).astype(int)
                else:
                    hiv_mapped = pd.to_numeric(hiv_data, errors='coerce').fillna(0).astype(int)

                hiv_positivo = (hiv_mapped == 1)
                complexidade.append(hiv_positivo)
                logger.info(f"   ‚úÖ HIV: {hiv_positivo.sum()} casos positivos")

            # M√∫ltiplas comorbidades
            if 'SCORE_COMORBIDADES' in self.df.columns:
                multiplas_comorbidades = (self.df['SCORE_COMORBIDADES'] >= 2)
                complexidade.append(multiplas_comorbidades)
                logger.info(f"   ‚úÖ COMORBIDADES: {multiplas_comorbidades.sum()} casos com ‚â•2")

            if not complexidade:
                logger.warning("‚ö†Ô∏è Nenhum crit√©rio de complexidade dispon√≠vel")
                return False

            caso_complexo = np.any(complexidade, axis=0).astype(int)
            self.df['CASO_COMPLEXO'] = caso_complexo
            self.derived_features.append('CASO_COMPLEXO')
            self._register_replacement('CASO_COMPLEXO', [], 'medium', 'partial')

            casos_complexos = caso_complexo.sum()
            total_casos = len(self.df)
            percentage = (casos_complexos / total_casos) * 100

            logger.info("‚úÖ CASO_COMPLEXO criado com sucesso!")
            logger.info(f"   üìä Casos complexos: {casos_complexos}/{total_casos} ({percentage:.1f}%)")

            return True

        except Exception as e:
            logger.error(f"‚ùå Erro ao criar CASO_COMPLEXO: {e}")
            return False

    # Aplicar os patches
    try:
        from features.selecao_features import TuberculosisFeatureSelector

        # Substituir m√©todos da classe
        TuberculosisFeatureSelector._create_score_comorbidades = _create_score_comorbidades_patched
        TuberculosisFeatureSelector._create_risco_social = _create_risco_social_patched
        TuberculosisFeatureSelector._create_caso_complexo = _create_caso_complexo_patched

        logger.info("‚úÖ Patches categ√≥ricos aplicados com sucesso √† classe TuberculosisFeatureSelector!")
        return True

    except ImportError as e:
        logger.error(f"‚ùå Erro ao importar TuberculosisFeatureSelector: {e}")
        return False
    except Exception as e:
        logger.error(f"‚ùå Erro ao aplicar patches: {e}")
        return False


if sys.platform == "win32":
    os.system("chcp 65001 > nul 2>&1")

os.environ["PYTHONIOENCODING"] = "utf-8"

# Adiciona path dos m√≥dulos
sys.path.append(str(Path(__file__).parent))
sys.path.append(str(Path(__file__).parent / "modules"))

def setup_logging(log_level: str = "INFO", log_file: str = None):
    """Configura sistema de logging """

    # Mapear os n√≠veis
    level_map = {
        'DEBUG': logging.DEBUG,
        'INFO': logging.INFO,
        'WARNING': logging.WARNING,
        'ERROR': logging.ERROR,
        'CRITICAL': logging.CRITICAL
    }

    level = level_map.get(log_level.upper(), logging.INFO)

    # LIMPA TODOS OS HANDLERS EXISTENTES
    root_logger = logging.getLogger()
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # REMOVE HANDLERS DE TODOS OS LOGGERS EXISTENTES
    for logger_name in logging.Logger.manager.loggerDict:
        logger_obj = logging.getLogger(logger_name)
        logger_obj.handlers.clear()
        logger_obj.propagate = True

    # CRIA HANDLER CUSTOM
    class EmojiSafeHandler(logging.StreamHandler):
        def emit(self, record):
            try:
                msg = self.format(record)
                if sys.platform == "win32":
                    print(msg, file=sys.stderr, flush=True)
                else:
                    sys.stderr.write(msg + '\n')
                    sys.stderr.flush()
            except (UnicodeEncodeError, AttributeError):
                # Se falhar, substituir emojis
                safe_msg = self._make_emoji_safe(msg)
                print(safe_msg, file=sys.stderr, flush=True)
            except Exception:
                try:
                    fallback_msg = record.getMessage().encode('ascii', 'replace').decode('ascii')
                    print(f"{record.levelname}: {fallback_msg}", file=sys.stderr, flush=True)
                except:
                    print(f"{record.levelname}: [ERRO DE ENCODING]", file=sys.stderr, flush=True)

        def _make_emoji_safe(self, text):
            """Substitui emojis por texto ASCII"""
            emoji_map = {
                "üö®": "[ALERTA]", "‚ùå": "[ERRO]", "‚ö†Ô∏è": "[AVISO]", "‚úÖ": "[OK]",
                "üîß": "[CONFIG]", "üìä": "[DADOS]", "üéØ": "[META]", "üèÜ": "[MELHOR]",
                "üìÑ": "[RELATORIO]", "üîç": "[BUSCA]", "üïê": "[TEMPO]", "ü§ñ": "[IA]",
                "üìã": "[LISTA]", "üéâ": "[SUCESSO]", "üè•": "[HOSPITAL]", "‚öôÔ∏è": "[GEAR]",
                "üìÅ": "[PASTA]", "üìù": "[NOTA]", "üöÄ": "[ROCKET]", "‚ñ∂Ô∏è": "[PLAY]",
                "‚è±Ô∏è": "[TIMER]", "üíæ": "[SAVE]", "üî•": "[FIRE]", "üìß": "[EMAIL]", "üì±": "[PHONE]",
                "üîÑ": "[DERIVADA]"  # Adiciona √≠cone para features derivadas
            }

            result = text
            for emoji, replacement in emoji_map.items():
                result = result.replace(emoji, replacement)
            return result

    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # Configura handler principal
    console_handler = EmojiSafeHandler()
    console_handler.setFormatter(formatter)

    # File handler
    handlers = [console_handler]
    if log_file:
        try:
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setFormatter(formatter)
            handlers.append(file_handler)
        except Exception as e:
            print(f"Aviso: Erro no log de arquivo: {e}")

    # Configura logging root
    logging.basicConfig(
        level=level,
        handlers=handlers,
        force=True
    )

    # TODOS os loggers usem este handler
    root_logger = logging.getLogger()
    root_logger.setLevel(level)

    # Configura propaga√ß√£o para todos os loggers existentes
    for logger_name in logging.Logger.manager.loggerDict:
        logger_obj = logging.getLogger(logger_name)
        logger_obj.propagate = True
        logger_obj.setLevel(logging.NOTSET)

# Configura logging inicial GLOBAL
setup_logging()

# DEFINE LOGGER AP√ìS CONFIGURA√á√ÉO
logger = logging.getLogger('TuberculosisAI')

for logger_name in ['AdvancedLeakageDetector', 'DataLeakageDetector', 'ClinicalTimelineAnalyzer',
                   'TuberculosisPredictor', 'ComprehensiveReportGenerator', 'FeatureSelector']:
    temp_logger = logging.getLogger(logger_name)
    temp_logger.propagate = True

try:
    from configs.config_manager import get_config_manager, ConfigManager
except ImportError:
    logger.warning("‚ö†Ô∏è Sistema de configura√ß√£o n√£o encontrado. Usando configura√ß√£o b√°sica.")
    ConfigManager = None

try:
    from features.selecao_features import run_feature_selection_for_main, TuberculosisFeatureSelector
    FEATURE_SELECTOR_AVAILABLE = True
    logger.info("‚úÖ Sistema de sele√ß√£o de features dispon√≠vel")
except ImportError:
    FEATURE_SELECTOR_AVAILABLE = False
    logger.error("‚ùå selecao_features.py n√£o encontrado!")

try:
    from modules.validacao_hipotese import run_statistical_validation as statistical_validation_func
    STATISTICAL_VALIDATION_AVAILABLE = True
    logger.info("‚úÖ M√≥dulo de valida√ß√£o estat√≠stica importado com sucesso")
except ImportError as e:
    STATISTICAL_VALIDATION_AVAILABLE = False
    logger.error(f"‚ùå Erro ao importar modules.validacao_hipotese: {e}")

class TuberculosisAISystem:
    """
    Sistema Principal da IA para Tuberculose Infantil
    COM SUBSTITUI√á√ÉO INTELIGENTE DE FEATURES
    Orquestra todos os microservi√ßos em sequ√™ncia l√≥gica
    """

    def __init__(self, config_file: str = None, config_overrides: Dict[str, Any] = None):

        # Carrega configura√ß√£o
        if ConfigManager:
            self.config_manager = get_config_manager(config_file)
            self.config = self.config_manager.config
        else:
            self.config = self._load_default_config()

        if config_overrides:
            self._apply_config_overrides(config_overrides)

        # Reconfigura logging com n√≠vel do config
        log_level = self.config.get('system', {}).get('log_level', 'INFO')
        setup_logging(log_level)

        # Inicializa sistema
        self.results = {}
        self.data_path = None
        self.output_dir = None
        self.start_time = None
        self.step_times = {}
        self.feature_selector = None

        # Verifica disponibilidade do seletor de features PRIMEIRO
        if not FEATURE_SELECTOR_AVAILABLE:
            logger.error("‚ùå SISTEMA N√ÉO PODE CONTINUAR SEM selecao_features.py!")
            raise ImportError("selecao_features.py √© obrigat√≥rio para o funcionamento")

        # Status do pipeline
        self.pipeline_status = {
            'feature_selection': False,
            'clinical_analysis': False,
            'leakage_detection': False,
            'model_training': False,
            'validacao_hipotese': False,
            'report_generation': False
        }

        # Valida depend√™ncias
        self._validate_dependencies()

        # Mostra cen√°rios que ser√£o executados
        scenarios = self._get_scenarios_from_config()
        logger.info(f"üéØ Cen√°rios configurados: {scenarios}")

        # Log inicial com foco na substitui√ß√£o inteligente
        system_info = self.config.get('system', {})
        logger.info(f"üè• {system_info.get('name', 'Sistema IA Tuberculose')} v{system_info.get('version', '1.0')}")
        logger.info("üìã Arquitetura: Microservi√ßos com SUBSTITUI√á√ÉO INTELIGENTE DE FEATURES")
        logger.info(f"‚öôÔ∏è Configura√ß√£o carregada: {len(self.config)} se√ß√µes")

        # Log da configura√ß√£o de substitui√ß√£o
        replacement_config = self.config.get('feature_selection', {}).get('feature_replacement', {})
        if replacement_config.get('enable_smart_replacement', True):
            logger.info("üîÑ SUBSTITUI√á√ÉO INTELIGENTE DE FEATURES HABILITADA")
            logger.info(f"   Estrat√©gia: {replacement_config.get('replacement_strategy', 'replace_originals')}")
            logger.info(f"   Priorizar derivadas: {replacement_config.get('prioritize_derived_features', True)}")
        else:
            logger.warning("‚ö†Ô∏è Substitui√ß√£o inteligente desabilitada")

        if self.config_manager:
            runtime_info = self.config_manager.get_runtime_info()
            logger.info(f"üìä Fontes de configura√ß√£o: {runtime_info['config_sources']}")

    def _apply_config_overrides(self, overrides: Dict[str, Any]):
        """Aplica overrides de configura√ß√£o"""
        for key, value in overrides.items():
            # Converte chaves com underscore para pontos
            if '_' in key:
                key = key.replace('_', '.')

            # Aplica override
            keys = key.split('.')
            current = self.config
            for k in keys[:-1]:
                if k not in current:
                    current[k] = {}
                current = current[k]
            current[keys[-1]] = value

            logger.info(f"üîß Override aplicado: {key} = {value}")

    def _validate_dependencies(self) -> bool:
        """Valida se todos os m√≥dulos necess√°rios existem"""
        required_modules = [
            'modules.analisador_temporal',
            'modules.detector_dataleak',
            'modules.treino',
            'modules.relatorio'
        ]

        missing_modules = []
        for module in required_modules:
            try:
                __import__(module)
            except ImportError:
                missing_modules.append(module)

        if missing_modules:
            logger.error(f"‚ùå M√≥dulos n√£o encontrados: {missing_modules}")
            return False

        logger.info("‚úÖ Todos os m√≥dulos necess√°rios encontrados")
        return True

    def _load_default_config(self) -> Dict[str, Any]:
        return {
            'system': {
                'name': 'Sistema de Predi√ß√£o Tuberculose Infantil',
                'version': '1.0.0',
                'log_level': 'INFO'
            },
            'feature_selection': {
                'scenarios': ['GERAL'],
                'max_features': 20,
                'use_temporal_critical': False,
                'feature_replacement': {
                    'enable_smart_replacement': True,
                    'replacement_strategy': 'replace_originals',
                    'prioritize_derived_features': True
                }
            },
            'model': {
                'use_tabpfn': True,
                'meta_model_type': 'auto',
                'cv_folds': 10,
                'max_features': 20,
                'test_size': 0.2,
                'validation_size': 0.2
            },
            'leakage_detection': {
                'temporal_threshold': 0.10,
                'missing_threshold': 0.20
            },
            'reports': {
                'generate_word': True,
                'generate_technical': True,
                'generate_executive': True,
                'create_visualizations': True
            },
            'pipeline': {
                'stop_on_critical_leakage': False,
                'save_checkpoints': True,
            }
        }

    def setup_environment(self, data_path: str = None, output_dir: str = None) -> bool:
        """
        Configura√ß√£o inicial do ambiente

        Args:
            data_path: Caminho para arquivo de dados (caso n√£o esteja setado em config.yaml)
            output_dir: Diret√≥rio de sa√≠da (caso n√£o esteja setado em config.yaml)
        """
        try:
            # Usa caminhos da configura√ß√£o se n√£o setados
            if not data_path:
                data_path = self.config.get('data', {}).get('input_path')

            if not output_dir:
                output_dir = self.config.get('data', {}).get('output_base_dir')

            # Valida arquivo de dados
            if not data_path:
                logger.error("‚ùå Caminho dos dados n√£o especificado")
                logger.error("üí° Use --data-path ou configure em config_local.yaml")
                return False

            self.data_path = Path(data_path)
            if not self.data_path.exists():
                logger.error(f"‚ùå Arquivo de dados n√£o encontrado: {data_path}")
                return False

            # Configura diret√≥rio de sa√≠da
            if output_dir:
                self.output_dir = Path(output_dir)
            else:
                self.output_dir = self.data_path.parent / "tb_ia_resultados"

            self.output_dir.mkdir(exist_ok=True)

            # Cria subdiret√≥rios
            subdirs = ["reports", "models", "logs", "visualizations", "checkpoints"]
            for subdir in subdirs:
                (self.output_dir / subdir).mkdir(exist_ok=True)

            # Configura log de arquivo
            log_file = self.output_dir / "logs" / f"tb_ia_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

            # Adiciona handler de arquivo ao logger
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setFormatter(logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            ))
            logging.getLogger().addHandler(file_handler)

            logger.info(f"‚úÖ Ambiente configurado:")
            logger.info(f"   üìÅ Dados: {self.data_path}")
            logger.info(f"   üìÅ Sa√≠da: {self.output_dir}")
            logger.info(f"   üìù Log: {log_file}")

            # Salva configura√ß√£o usada
            if self.config_manager:
                config_used_path = self.output_dir / "logs" / "config_used.yaml"
                self.config_manager.save_config(str(config_used_path))
                logger.info(f"   ‚öôÔ∏è Configura√ß√£o salva: {config_used_path}")

            return True

        except Exception as e:
            logger.error(f"‚ùå Erro na configura√ß√£o: {e}")
            return False

    def _get_scenarios_from_config(self) -> List[str]:
        """Obt√©m cen√°rios configurados"""
        feature_config = self.config.get('feature_selection', {})
        scenarios = feature_config.get('scenarios', ['GERAL'])

        # Valida cen√°rios
        valid_scenarios = ['GERAL', 'MASCULINO', 'FEMININO', 'NEGROS_PARDOS', 'OUTROS_RACA']
        validated_scenarios = [s for s in scenarios if s in valid_scenarios]

        if not validated_scenarios:
            logger.warning("‚ö†Ô∏è Nenhum cen√°rio v√°lido encontrado, usando GERAL")
            validated_scenarios = ['GERAL']

        return validated_scenarios

    def run_feature_selection(self) -> bool:
        """ETAPA 1: Sele√ß√£o de Features com SUBSTITUI√á√ÉO INTELIGENTE (SEMPRE OBRIGAT√ìRIA)"""
        try:
            step_start = time.time()
            logger.info("\n" + "=" * 70)
            logger.info("üîß ETAPA 1: SELE√á√ÉO DE FEATURES COM SUBSTITUI√á√ÉO INTELIGENTE")
            logger.info("=" * 70)

            # Obter cen√°rios da configura√ß√£o
            scenarios_to_run = self._get_scenarios_from_config()

            logger.info(f"üìä Cen√°rios selecionados: {scenarios_to_run}")
            logger.info(f"üìÅ Arquivo de dados: {self.data_path}")

            # Log da estrat√©gia de substitui√ß√£o
            replacement_config = self.config.get('feature_selection', {}).get('feature_replacement', {})
            if replacement_config.get('enable_smart_replacement', True):
                logger.info("üîÑ ESTRAT√âGIA DE SUBSTITUI√á√ÉO:")
                logger.info(f"   ‚úÖ SCORE_COMORBIDADES ‚Üí substitui 7 features individuais")
                logger.info(f"   ‚úÖ RISCO_SOCIAL ‚Üí substitui popula√ß√µes especiais")
                logger.info(f"   ‚úÖ TEMPO_INICIO_CAT ‚Üí substitui vers√£o cont√≠nua")
                logger.info(f"   ‚úÖ Features derivadas priorizadas na sele√ß√£o")

            # Executar sele√ß√£o de features com substitui√ß√µes
            self.feature_selector = run_feature_selection_for_main(
                data_path=str(self.data_path),
                config=self.config,
                scenarios=scenarios_to_run
            )

            if not self.feature_selector:
                logger.error("‚ùå Falha na sele√ß√£o de features")
                return False

            # Armazenar resultados incluindo informa√ß√µes de substitui√ß√£o
            replacement_summary = self.feature_selector.get_replacement_summary()

            self.results['feature_selection'] = {
                'selector': self.feature_selector,
                'scenarios_processed': self.feature_selector.list_processed_scenarios(),
                'derived_features': self.feature_selector.derived_features,
                'replaced_features': list(self.feature_selector.replaced_features),
                'replacement_mappings': self.feature_selector.replacement_mappings,
                'replacement_summary': replacement_summary,
                'scenarios_configured': scenarios_to_run,
                'config_used': self.config.get('feature_selection', {}),
                'timestamp': datetime.now()
            }

            self.pipeline_status['feature_selection'] = True
            self.step_times['feature_selection'] = time.time() - step_start

            if self.config.get('pipeline', {}).get('save_checkpoints', True):
                self.save_checkpoint('feature_selection')

            # Salvar resumo da sele√ß√£o COM INFORMA√á√ïES DE SUBSTITUI√á√ÉO
            summary_path = self.output_dir / "reports" / "01_feature_selection_summary.txt"
            self.feature_selector.save_results_summary(str(summary_path))

            # Mostrar resumo com foco nas substitui√ß√µes
            processed_scenarios = self.feature_selector.list_processed_scenarios()
            logger.info(f"‚úÖ Sele√ß√£o conclu√≠da para {len(processed_scenarios)} cen√°rios")
            logger.info(f"üîÑ Features derivadas criadas: {len(self.feature_selector.derived_features)}")
            logger.info(f"üîÑ Features originais substitu√≠das: {len(self.feature_selector.replaced_features)}")

            # Resumo de efetividade das substitui√ß√µes
            total_derived_used = 0
            total_replaced_still_used = 0

            for scenario in processed_scenarios:
                data, features = self.feature_selector.get_data_for_scenario(scenario)
                derived_count = len([f for f in features if f in self.feature_selector.derived_features])
                replaced_count = len([f for f in features if f in self.feature_selector.replaced_features])

                total_derived_used += derived_count
                total_replaced_still_used += replaced_count

                logger.info(f"   üéØ {scenario}: {len(features)} features ({derived_count} derivadas), {len(data)} registros")
                if replaced_count > 0:
                    logger.warning(f"      ‚ö†Ô∏è {replaced_count} features substitu√≠das ainda em uso")
                else:
                    logger.info(f"      ‚úÖ Substitui√ß√µes efetivas")

            # An√°lise geral de efetividade
            if total_replaced_still_used == 0:
                logger.info(f"   ‚úÖ SUBSTITUI√á√ïES 100% EFETIVAS - features originais n√£o est√£o sendo usadas")
            else:
                logger.warning(f"   ‚ö†Ô∏è {total_replaced_still_used} features substitu√≠das ainda em uso - revisar configura√ß√£o")

            # Log das substitui√ß√µes realizadas
            if replacement_summary['replacement_enabled']:
                logger.info(f"\nüîÑ RESUMO DAS SUBSTITUI√á√ïES APLICADAS:")
                logger.info(f"   Features derivadas: {replacement_summary['derived_features_created']}")
                if replacement_summary['replaced_features']:
                    logger.info(f"   Features substitu√≠das: {replacement_summary['replaced_features']}")
                logger.info(f"   Estrat√©gia: {replacement_summary['replacement_strategy']}")

            return True

        except Exception as e:
            logger.error(f"‚ùå Erro na sele√ß√£o de features: {e}")
            logger.error(traceback.format_exc())
            if self.config.get('pipeline', {}).get('stop_on_failure', False):
                raise
            return False

    def run_clinical_timeline_analysis(self) -> bool:
        """
        ETAPA 2: An√°lise da Linha Temporal Cl√≠nica das Features Selecionadas E DERIVADAS
        Identifica quando cada informa√ß√£o est√° dispon√≠vel, considerando substitui√ß√µes
        """
        try:
            step_start = time.time()
            logger.info("\n" + "=" * 70)
            logger.info("üïê ETAPA 2: AN√ÅLISE TEMPORAL COM FEATURES DERIVADAS")
            logger.info("=" * 70)

            if not self.feature_selector:
                logger.error("‚ùå Sele√ß√£o de features n√£o executada!")
                return False

            from modules.analisador_temporal import ClinicalTimelineAnalyzer

            # Inicializar analisador com informa√ß√µes de substitui√ß√£o
            analyzer = ClinicalTimelineAnalyzer(feature_selector=self.feature_selector)

            # Executa an√°lise temporal base
            timeline_results = analyzer.analyze_clinical_timeline()
            feature_categories = analyzer.create_clinical_feature_categories()

            # An√°lise espec√≠fica das features selecionadas por cen√°rio
            selected_features_analysis = {}
            processed_scenarios = self.feature_selector.list_processed_scenarios()

            logger.info(f"üîÑ Analisando features derivadas criadas:")
            for derived_feature in self.feature_selector.derived_features:
                logger.info(f"   ‚úÖ {derived_feature} (considerada temporalmente segura)")

            for scenario in processed_scenarios:
                data, features = self.feature_selector.get_data_for_scenario(scenario)

                logger.info(f"üéØ Analisando features do cen√°rio {scenario}")

                # Avalia cada feature selecionada (incluindo derivadas)
                features_risk = {}
                for feature in features:
                    risk_assessment = analyzer.get_feature_risk_assessment(feature)
                    features_risk[feature] = risk_assessment

                # Valida√ß√£o das features nos dados
                validation = analyzer.validate_features_in_data(list(data.columns))

                # An√°lise espec√≠fica de substitui√ß√µes
                derived_in_scenario = [f for f in features if f in self.feature_selector.derived_features]
                replaced_in_scenario = [f for f in features if f in self.feature_selector.replaced_features]

                selected_features_analysis[scenario] = {
                    'features_used': features,
                    'features_risk': features_risk,
                    'data_validation': validation,
                    'total_features': len(features),
                    'safe_features': [f for f, r in features_risk.items() if r['risk_level'] == 'BAIXO'],
                    'risky_features': [f for f, r in features_risk.items() if r['risk_level'] in ['ALTO', 'CR√çTICO']],
                    'derived_features_used': derived_in_scenario,
                    'replaced_features_still_used': replaced_in_scenario,
                    'replacement_effectiveness': len(replaced_in_scenario) == 0  # True se nenhuma substitu√≠da est√° sendo usada
                }

                safe_count = len(selected_features_analysis[scenario]['safe_features'])
                derived_count = len(derived_in_scenario)
                replaced_count = len(replaced_in_scenario)

                logger.info(f"   ‚úÖ Features seguras: {safe_count}/{len(features)}")
                logger.info(f"   üîÑ Features derivadas: {derived_count}/{len(features)}")
                if replaced_count > 0:
                    logger.warning(f"   ‚ö†Ô∏è Features substitu√≠das ainda em uso: {replaced_count}")
                else:
                    logger.info(f"   ‚úÖ Substitui√ß√µes efetivas: originais n√£o est√£o sendo usadas")

            # Salva resultados
            self.results['clinical_analysis'] = {
                'timeline_results': timeline_results,
                'feature_categories': feature_categories,
                'temporal_features': analyzer.get_temporal_suspicious_features(),
                'safe_features': analyzer.get_safe_features(),
                'derived_features': analyzer.get_derived_features(),
                'replaced_features': analyzer.get_replaced_features(),
                'selected_features_analysis': selected_features_analysis,
                'scenarios_analyzed': processed_scenarios,
                'replacement_analysis': analyzer.replacement_analysis if hasattr(analyzer, 'replacement_analysis') else {},
                'timestamp': datetime.now()
            }

            # Salva relat√≥rio da an√°lise temporal
            timeline_report_path = self.output_dir / "reports" / "02_clinical_timeline_analysis.txt"
            analyzer.save_timeline_report(timeline_report_path)

            # Salva an√°lise espec√≠fica das features selecionadas
            self._save_selected_features_temporal_analysis(selected_features_analysis)

            self.pipeline_status['clinical_analysis'] = True
            self.step_times['clinical_analysis'] = time.time() - step_start

            # Checkpoint
            if self.config.get('pipeline', {}).get('save_checkpoints', True):
                self.save_checkpoint('clinical_analysis')

            logger.info("‚úÖ An√°lise temporal das features selecionadas E DERIVADAS conclu√≠da")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erro na an√°lise temporal: {e}")
            logger.error(traceback.format_exc())
            if self.config.get('pipeline', {}).get('stop_on_failure', False):
                raise
            return False

    def _save_selected_features_temporal_analysis(self, analysis: Dict[str, Any]):
        """Salva an√°lise temporal espec√≠fica das features selecionadas COM SUBSTITUI√á√ïES"""
        try:
            report_path = self.output_dir / "reports" / "02_selected_features_temporal_analysis.txt"

            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("AN√ÅLISE TEMPORAL DAS FEATURES SELECIONADAS COM SUBSTITUI√á√ïES\n")
                f.write("=" * 80 + "\n\n")

                for scenario, data in analysis.items():
                    f.write(f"CEN√ÅRIO: {scenario}\n")
                    f.write("-" * 40 + "\n")
                    f.write(f"Total de features: {data['total_features']}\n")
                    f.write(f"Features seguras: {len(data['safe_features'])}\n")
                    f.write(f"Features arriscadas: {len(data['risky_features'])}\n")

                    # Informa√ß√µes de substitui√ß√£o
                    derived_count = len(data.get('derived_features_used', []))
                    replaced_count = len(data.get('replaced_features_still_used', []))
                    f.write(f"Features derivadas utilizadas: {derived_count}\n")
                    f.write(f"Features substitu√≠das ainda em uso: {replaced_count}\n")
                    f.write(f"Efetividade das substitui√ß√µes: {'‚úÖ SIM' if data.get('replacement_effectiveness', False) else '‚ö†Ô∏è PARCIAL'}\n\n")

                    f.write("FEATURES SEGURAS (Temporalmente):\n")
                    for feature in data['safe_features']:
                        marker = "üîÑ" if feature in data.get('derived_features_used', []) else "‚úÖ"
                        suffix = " (DERIVADA)" if feature in data.get('derived_features_used', []) else ""
                        f.write(f"  {marker} {feature}{suffix}\n")

                    f.write("\nFEATURES ARRISCADAS (Temporalmente):\n")
                    for feature in data['risky_features']:
                        risk_info = data['features_risk'][feature]
                        marker = "‚ö†Ô∏è"
                        if feature in data.get('replaced_features_still_used', []):
                            marker = "üö®"
                            suffix = " (SUBSTITU√çDA - REVISAR)"
                        else:
                            suffix = ""
                        f.write(f"  {marker} {feature}{suffix} - Risco: {risk_info['risk_level']}\n")
                        f.write(f"     Categoria: {risk_info['category']}\n")
                        f.write(f"     Momento: {risk_info['moment']}\n")

                    # An√°lise de substitui√ß√µes por cen√°rio
                    if data.get('derived_features_used'):
                        f.write(f"\nFEATURES DERIVADAS UTILIZADAS:\n")
                        for feature in data['derived_features_used']:
                            f.write(f"  üîÑ {feature}\n")

                    if data.get('replaced_features_still_used'):
                        f.write(f"\nFEATURES SUBSTITU√çDAS AINDA EM USO (Revisar):\n")
                        for feature in data['replaced_features_still_used']:
                            f.write(f"  üö® {feature} - considere remover da sele√ß√£o\n")

                    f.write("\n" + "=" * 60 + "\n\n")

            logger.info(f"üìÑ An√°lise temporal das features COM SUBSTITUI√á√ïES salva: {report_path}")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao salvar an√°lise temporal das features: {e}")

    def run_leakage_detection(self) -> bool:
        """
        ETAPA 3: Detec√ß√£o de Data Leakage nas Features Selecionadas COM DERIVADAS
        Identifica vazamentos √≥bvios nos dados considerando substitui√ß√µes
        """
        try:
            step_start = time.time()
            logger.info("\n" + "=" * 70)
            logger.info("üö® ETAPA 3: DETEC√á√ÉO DE DATA LEAKAGE COM FEATURES DERIVADAS")
            logger.info("=" * 70)

            if not self.feature_selector:
                logger.error("‚ùå Sele√ß√£o de features n√£o executada!")
                return False

            from modules.detector_dataleak import DataLeakageDetector

            # Log sobre tratamento de features derivadas
            logger.info("üîÑ Features derivadas s√£o consideradas temporalmente SEGURAS por constru√ß√£o")
            logger.info(f"   Features derivadas: {self.feature_selector.derived_features}")

            # An√°lise de leakage por cen√°rio
            leakage_results_by_scenario = {}
            processed_scenarios = self.feature_selector.list_processed_scenarios()

            for scenario in processed_scenarios:
                logger.info(f"\nüéØ Analisando leakage no cen√°rio: {scenario}")

                # Obter dados e features do cen√°rio
                data, features = self.feature_selector.get_data_for_scenario(scenario)

                if len(data) < 50:
                    logger.warning(f"‚ö†Ô∏è Poucos dados para an√°lise de {scenario}")
                    continue

                # Criar detector para este cen√°rio
                detector = DataLeakageDetector()

                # Salvar dados tempor√°rios (s√≥ com features selecionadas)
                temp_dir = self.output_dir / "temp"
                temp_dir.mkdir(exist_ok=True)
                temp_data_path = temp_dir / f"leakage_data_{scenario}.csv"

                # Manter apenas features selecionadas + target
                columns_to_keep = features + ['SITUA_ENCE'] if 'SITUA_ENCE' in data.columns else features
                columns_available = [col for col in columns_to_keep if col in data.columns]

                data_for_leakage = data[columns_available]
                data_for_leakage.to_csv(temp_data_path, index=False)

                # Carregar dados no detector
                if not detector.load_and_preprocess(str(temp_data_path)):
                    logger.error(f"‚ùå Falha ao carregar dados para detec√ß√£o de leakage - {scenario}")
                    continue

                # Executa detec√ß√£o espec√≠fica para as features selecionadas
                leakage_results = detector.generate_leakage_report()

                # An√°lise espec√≠fica das features selecionadas considerando derivadas
                features_leakage_analysis = {}
                derived_count = 0
                for feature in features:
                    if feature in self.feature_selector.derived_features:
                        # Features derivadas s√£o consideradas seguras
                        features_leakage_analysis[feature] = {
                            'status': 'SEGURA',
                            'reason': 'Feature derivada - constru√≠da com dados do momento inicial'
                        }
                        derived_count += 1
                    elif feature in detector.suspicious_features:
                        features_leakage_analysis[feature] = {
                            'status': 'SUSPEITA',
                            'reason': 'Identificada como temporalmente suspeita'
                        }
                    else:
                        features_leakage_analysis[feature] = {
                            'status': 'SEGURA',
                            'reason': 'N√£o identificada como suspeita'
                        }

                # Contar apenas features originais suspeitas (n√£o derivadas)
                original_suspicious = [f for f in features if f in detector.suspicious_features and f not in self.feature_selector.derived_features]

                leakage_results_by_scenario[scenario] = {
                    'general_results': leakage_results,
                    'features_analysis': features_leakage_analysis,
                    'risk_level': leakage_results.get('risk_level', 'UNKNOWN'),
                    'suspicious_count': len(original_suspicious),  # S√≥ conta originais suspeitas
                    'total_features': len(features),
                    'derived_features_count': derived_count,
                    'derived_features_safe': derived_count  # Todas derivadas s√£o consideradas seguras
                }

                # Limpar arquivo tempor√°rio
                temp_data_path.unlink(missing_ok=True)

                suspicious_count = leakage_results_by_scenario[scenario]['suspicious_count']
                total_count = leakage_results_by_scenario[scenario]['total_features']
                risk_level = leakage_results_by_scenario[scenario]['risk_level']

                logger.info(f"   üìä Features suspeitas (originais): {suspicious_count}/{total_count}")
                logger.info(f"   üîÑ Features derivadas (seguras): {derived_count}/{total_count}")
                logger.info(f"   üö® Risco geral: {risk_level}")

            # Determinar risco geral do sistema
            overall_risk = self._determine_overall_leakage_risk(leakage_results_by_scenario)

            # Salva resultados
            self.results['leakage_detection'] = {
                'results_by_scenario': leakage_results_by_scenario,
                'overall_risk_level': overall_risk,
                'scenarios_analyzed': list(leakage_results_by_scenario.keys()),
                'derived_features_treatment': 'considered_safe',
                'timestamp': datetime.now()
            }

            # Salva relat√≥rio de leakage
            leakage_report_path = self.output_dir / "reports" / "03_leakage_detection_report.txt"
            self._save_integrated_leakage_report(leakage_report_path, leakage_results_by_scenario, overall_risk)

            self.pipeline_status['leakage_detection'] = True
            self.step_times['leakage_detection'] = time.time() - step_start

            # Checkpoint
            if self.config.get('pipeline', {}).get('save_checkpoints', True):
                self.save_checkpoint('leakage_detection')

            # Verifica se pode continuar
            stop_on_critical = self.config.get('pipeline', {}).get('stop_on_critical_leakage', False)

            if overall_risk == 'CRITICAL' and stop_on_critical:
                logger.error("üö® RISCO CR√çTICO detectado - Pipeline interrompido conforme configura√ß√£o")
                return False
            elif overall_risk == 'HIGH':
                logger.warning("‚ö†Ô∏è RISCO ALTO de data leakage detectado - prosseguindo com cautela")
            else:
                logger.info(f"‚úÖ Detec√ß√£o de leakage conclu√≠da - Risco: {overall_risk}")
                logger.info(f"üîÑ Features derivadas reduzem risco temporal significativamente")

            return True

        except Exception as e:
            logger.error(f"‚ùå Erro na detec√ß√£o de leakage: {e}")
            logger.error(traceback.format_exc())
            if self.config.get('pipeline', {}).get('stop_on_failure', False):
                raise
            return False

    def _determine_overall_leakage_risk(self, results_by_scenario: Dict[str, Any]) -> str:
        """Determina risco geral baseado em todos os cen√°rios"""
        risk_levels = []

        for scenario, results in results_by_scenario.items():
            risk_levels.append(results['risk_level'])

        if 'CRITICAL' in risk_levels:
            return 'CRITICAL'
        elif 'HIGH' in risk_levels:
            return 'HIGH'
        elif 'MODERATE' in risk_levels:
            return 'MODERATE'
        else:
            return 'LOW'

    def _save_integrated_leakage_report(self, report_path: Path, results_by_scenario: Dict[str, Any],
                                        overall_risk: str):
        """Salva relat√≥rio integrado de leakage COM INFORMA√á√ïES DE SUBSTITUI√á√ÉO"""
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("RELAT√ìRIO DE DETEC√á√ÉO DE DATA LEAKAGE COM FEATURES DERIVADAS\n")
                f.write("An√°lise das Features Selecionadas por Cen√°rio\n")
                f.write("=" * 80 + "\n\n")

                f.write(f"RISCO GERAL DO SISTEMA: {overall_risk}\n")
                f.write(f"TRATAMENTO DE FEATURES DERIVADAS: Consideradas temporalmente seguras\n\n")

                for scenario, results in results_by_scenario.items():
                    f.write(f"CEN√ÅRIO: {scenario}\n")
                    f.write("-" * 40 + "\n")
                    f.write(f"Risco: {results['risk_level']}\n")
                    f.write(f"Features analisadas: {results['total_features']}\n")
                    f.write(f"Features suspeitas (originais): {results['suspicious_count']}\n")
                    f.write(f"Features derivadas (seguras): {results.get('derived_features_count', 0)}\n\n")

                    f.write("AN√ÅLISE POR FEATURE:\n")
                    for feature, analysis in results['features_analysis'].items():
                        if analysis['status'] == 'SUSPEITA':
                            status_icon = "‚ö†Ô∏è"
                        elif 'derivada' in analysis['reason'].lower():
                            status_icon = "üîÑ"
                        else:
                            status_icon = "‚úÖ"

                        f.write(f"  {status_icon} {feature}: {analysis['status']}\n")
                        f.write(f"     Motivo: {analysis['reason']}\n")

                    f.write("\n" + "=" * 60 + "\n\n")

            logger.info(f"üìÑ Relat√≥rio de leakage COM SUBSTITUI√á√ïES salvo: {report_path}")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao salvar relat√≥rio de leakage: {e}")

    def run_model_training(self) -> bool:
        """ETAPA 4: Treinamento usando Features Selecionadas COM OTIMIZA√á√ÉO PARA DERIVADAS"""
        try:
            step_start = time.time()
            logger.info("\n" + "=" * 70)
            logger.info("ü§ñ ETAPA 4: TREINAMENTO OTIMIZADO PARA FEATURES DERIVADAS")
            logger.info("=" * 70)

            if not self.feature_selector:
                logger.error("‚ùå Sele√ß√£o de features n√£o executada!")
                return False

            from modules.treino import TuberculosisPredictor

            processed_scenarios = self.feature_selector.list_processed_scenarios()
            training_results = {}

            logger.info("üîÑ Treinamento otimizado para features categ√≥ricas derivadas")

            # Treinar modelo para cada cen√°rio processado
            for scenario in processed_scenarios:
                logger.info(f"\nüéØ Treinando modelo: {scenario}")

                # Obter dados e features do cen√°rio
                data, features = self.feature_selector.get_data_for_scenario(scenario)

                if len(data) < 100:
                    logger.warning(f"‚ö†Ô∏è Poucos dados para {scenario}: {len(data)}")
                    continue

                if len(features) == 0:
                    logger.warning(f"‚ö†Ô∏è Nenhuma feature para {scenario}")
                    continue

                # An√°lise das features
                derived_count = len([f for f in features if f in self.feature_selector.derived_features])
                original_count = len(features) - derived_count

                # Verificar distribui√ß√£o do target
                target_dist = data['SITUA_ENCE'].value_counts()
                logger.info(f"   üìä Dados: {len(data)} registros")
                logger.info(f"   üéØ Target: {dict(target_dist)}")
                logger.info(f"   üîß Features totais: {len(features)}")
                logger.info(f"   üîÑ Features derivadas: {derived_count}")
                logger.info(f"   üìä Features originais: {original_count}")

                # Treinar modelo individual com otimiza√ß√£o para derivadas
                model_result = self._train_single_model(data, features, scenario)

                if model_result:
                    training_results[scenario] = model_result
                    logger.info(f"   ‚úÖ Modelo {scenario} treinado com sucesso")

                    # Log da performance
                    if 'predictor' in model_result and hasattr(model_result['predictor'], 'results'):
                        metrics = model_result['predictor'].results
                        acc = metrics.get('balanced_accuracy', 0)
                        f1 = metrics.get('f1_score', 0)
                        logger.info(f"   üìà Acur√°cia: {acc:.3f}, F1: {f1:.3f}")

                        # Log sobre features derivadas utilizadas
                        derived_used = len([f for f in model_result['features_used'] if f in self.feature_selector.derived_features])
                        logger.info(f"   üîÑ Features derivadas no modelo: {derived_used}")
                else:
                    logger.error(f"   ‚ùå Falha no treinamento de {scenario}")

            if not training_results:
                logger.error("‚ùå Nenhum modelo treinado com sucesso")
                return False

            # Encontrar melhor modelo
            best_scenario = None
            best_score = 0
            best_predictor = None

            for scenario, result in training_results.items():
                if 'predictor' in result and hasattr(result['predictor'], 'results'):
                    acc = result['predictor'].results.get('balanced_accuracy', 0)
                    if acc > best_score:
                        best_score = acc
                        best_scenario = scenario
                        best_predictor = result['predictor']

            # Armazenar resultados em formato compat√≠vel
            self.results['model_training'] = {
                'scenarios': training_results,
                'best_scenario': best_scenario,
                'config_used': self.config.get('model', {}),
                'derived_features_optimization': True,
                'timestamp': datetime.now()
            }

            # Adiciona dados do melhor modelo no formato esperado pelo relat√≥rio
            if best_predictor:
                self.results['model_training']['predictor'] = best_predictor
                self.results['model_training']['results'] = best_predictor.results
                self.results['model_training']['best_meta_name'] = getattr(best_predictor, 'best_meta_name', 'N/A')

            self.pipeline_status['model_training'] = True
            self.step_times['model_training'] = time.time() - step_start

            # Salvar modelos
            self._save_trained_models(training_results)

            # An√°lise comparativa com foco em substitui√ß√µes
            self._analyze_training_results(training_results)

            if best_predictor:
                from parametros import extract_from_trained_predictor
                logger.info("üìã Extraindo par√¢metros reais do modelo treinado...")

                # Extrai par√¢metros do melhor modelo com informa√ß√µes do treinamento
                params_file = extract_from_trained_predictor(
                    best_predictor,
                    str(self.output_dir / "parametros_treino_executado.txt")
                )

                # Adiciona informa√ß√µes de configura√ß√£o e resultados do pipeline
                from parametros import extract_from_pipeline_results
                extract_from_pipeline_results(
                    self.results,
                    self.config,
                    training_results,
                    str(self.output_dir / "parametros_pipeline_completo.txt")
                )

                logger.info(f"‚úÖ Par√¢metros do treino salvos em: {params_file}")

            if self.config.get('pipeline', {}).get('save_checkpoints', True):
                self.save_checkpoint('model_training')

            logger.info("‚úÖ Treinamento otimizado para features derivadas conclu√≠do")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erro no treinamento: {e}")
            logger.error(traceback.format_exc())
            if self.config.get('pipeline', {}).get('stop_on_failure', False):
                raise
            return False

    def _train_single_model(self, data: Any, features: List[str], scenario: str) -> Optional[Dict[str, Any]]:
        """Treina um modelo individual para um cen√°rio COM FEATURES DERIVADAS"""
        try:
            from modules.treino import TuberculosisPredictor

            # Criar diret√≥rio tempor√°rio
            temp_dir = self.output_dir / "temp"
            temp_dir.mkdir(exist_ok=True)

            # Salvar dados tempor√°rios para o preditor
            temp_data_path = temp_dir / f"data_{scenario}.csv"
            data.to_csv(temp_data_path, index=False)

            # Configurar preditor COM SUPORTE A FEATURES DERIVADAS
            model_config = self.config.get('model', {})
            predictor = TuberculosisPredictor(
                use_tabpfn=model_config.get('use_tabpfn', True),
                meta_model_type=model_config.get('meta_model_selection', 'auto'),
                cv_folds=model_config.get('cv_folds', 10),
                feature_selector=self.feature_selector,  # Passa o feature selector
                config=self.config  # Passa toda a configura√ß√£o
            )

            predictor.feature_selector = ensure_feature_selector_compatibility(predictor.feature_selector)

            # Carregar e processar dados
            if not predictor.load_data(str(temp_data_path)):
                logger.error(f"‚ùå Falha ao carregar dados tempor√°rios para {scenario}")
                return None

            # Preprocessar com features selecionadas
            if not predictor.preprocess_data():
                logger.error(f"‚ùå Falha no pr√©-processamento para {scenario}")
                return None

            # Filtrar features selecionadas
            available_features = [f for f in features if f in predictor.X.columns]
            if len(available_features) < 3:
                logger.warning(f"‚ö†Ô∏è Muito poucas features dispon√≠veis para {scenario}: {len(available_features)}")
                return None

            # Ajustar dados para features selecionadas
            predictor.X = predictor.X[available_features]
            predictor.feature_names = available_features
            predictor.selected_features = available_features

            # Treinar modelo
            if not predictor.train_model():
                logger.error(f"‚ùå Falha no treinamento para {scenario}")
                return None

            # Limpar arquivo tempor√°rio
            temp_data_path.unlink(missing_ok=True)

            return {
                'predictor': predictor,
                'scenario': scenario,
                'features_used': available_features,
                'metrics': predictor.results,
                'cv_results': getattr(predictor, 'cv_results', {}),
                'best_meta_name': getattr(predictor, 'best_meta_name', 'N/A'),
                'derived_features_used': [f for f in available_features if f in self.feature_selector.derived_features]
            }

        except Exception as e:
            logger.error(f"‚ùå Erro no treinamento individual de {scenario}: {e}")
            return None

    def _save_trained_models(self, training_results: Dict[str, Any]):
        """Salva modelos treinados"""
        try:
            models_dir = self.output_dir / "models"
            models_dir.mkdir(exist_ok=True)

            for scenario, result in training_results.items():
                if 'predictor' in result:
                    model_path = models_dir / f"model_{scenario}.pkl"
                    result['predictor'].save_model(str(model_path))
                    logger.info(f"üíæ Modelo {scenario} salvo: {model_path.name}")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao salvar modelos: {e}")

    def _analyze_training_results(self, training_results: Dict[str, Any]):
        """An√°lise comparativa dos resultados COM FOCO EM SUBSTITUI√á√ïES"""
        logger.info(f"\nüìä AN√ÅLISE COMPARATIVA DOS MODELOS COM FEATURES DERIVADAS:")
        logger.info("-" * 50)

        for scenario, result in training_results.items():
            if 'predictor' in result and hasattr(result['predictor'], 'results'):
                metrics = result['predictor'].results
                derived_used = result.get('derived_features_used', [])

                logger.info(f"\nüéØ {scenario}:")
                logger.info(f"   üìà Acur√°cia Balanceada: {metrics.get('balanced_accuracy', 0):.3f}")
                logger.info(f"   üéØ F1-Score: {metrics.get('f1_score', 0):.3f}")
                logger.info(f"   üìä AUC: {metrics.get('auc_score', 0):.3f}")
                logger.info(f"   üèÖ Meta-modelo: {result.get('best_meta_name', 'N/A')}")
                logger.info(f"   üîß Features totais: {len(result.get('features_used', []))}")
                logger.info(f"   üîÑ Features derivadas: {len(derived_used)}")
                if derived_used:
                    logger.info(f"      Derivadas usadas: {derived_used}")

        # Encontrar melhor modelo
        best_scenario = None
        best_score = 0
        for scenario, result in training_results.items():
            if 'predictor' in result and hasattr(result['predictor'], 'results'):
                score = result['predictor'].results.get('balanced_accuracy', 0)
                if score > best_score:
                    best_score = score
                    best_scenario = scenario

        if best_scenario:
            logger.info(f"\nüèÜ MELHOR MODELO: {best_scenario} (Acur√°cia: {best_score:.3f})")
            best_result = training_results[best_scenario]
            best_derived = best_result.get('derived_features_used', [])
            if best_derived:
                logger.info(f"   üîÑ Features derivadas no melhor modelo: {best_derived}")

    def run_report_generation(self) -> bool:
        """
        ETAPA 5: Gera√ß√£o de Relat√≥rios Completos COM AN√ÅLISE DE SUBSTITUI√á√ïES
        Consolida todos os resultados em relat√≥rios detalhados
        """
        try:
            step_start = time.time()
            logger.info("\n" + "="*70)
            logger.info("üìÑ ETAPA 5: GERA√á√ÉO DE RELAT√ìRIOS COM AN√ÅLISE DE SUBSTITUI√á√ïES")
            logger.info("="*70)

            from modules.relatorio import ComprehensiveReportGenerator

            generator = ComprehensiveReportGenerator(
                results=self.results,
                output_dir=self.output_dir,
                config=self.config
            )

            reports_config = self.config.get('reports', {})
            generated_files = []

            # Log sobre relat√≥rios com substitui√ß√µes
            logger.info("üìã Relat√≥rios incluir√£o an√°lise detalhada das substitui√ß√µes de features")

            # Gera relat√≥rio Word completo
            if reports_config.get('generate_word', True):
                word_report_path = generator.generate_word_report()
                if word_report_path:
                    generated_files.append(word_report_path)
                    logger.info(f"üìÑ Relat√≥rio Word: {Path(word_report_path).name}")

            # Gera relat√≥rio t√©cnico
            if reports_config.get('generate_technical', True):
                technical_report_path = generator.generate_technical_report()
                if technical_report_path:
                    generated_files.append(technical_report_path)
                    logger.info(f"üîß Relat√≥rio T√©cnico: {Path(technical_report_path).name}")

            # Gera visualiza√ß√µes
            if reports_config.get('create_visualizations', True):
                viz_paths = generator.generate_visualizations()
                generated_files.extend(viz_paths)
                logger.info(f"üìä Visualiza√ß√µes: {len(viz_paths)} arquivos gerados")

            # Gera resumo
            if reports_config.get('generate_executive', True):
                executive_summary_path = generator.generate_executive_summary()
                if executive_summary_path:
                    generated_files.append(executive_summary_path)
                    logger.info(f"üìã Resumo : {Path(executive_summary_path).name}")

            # Gera export JSON
            if reports_config.get('generate_json_export', True):
                json_export_path = generator.export_summary_json()
                if json_export_path:
                    generated_files.append(json_export_path)
                    logger.info(f"üìä Export JSON: {Path(json_export_path).name}")

            self.results['report_generation'] = {
                'generated_files': generated_files,
                'reports_config': reports_config,
                'includes_substitution_analysis': True,
                'timestamp': datetime.now()
            }

            self.pipeline_status['report_generation'] = True
            self.step_times['report_generation'] = time.time() - step_start

            # Checkpoint final
            if self.config.get('pipeline', {}).get('save_checkpoints', True):
                self.save_checkpoint('report_generation')

            logger.info("‚úÖ Gera√ß√£o de relat√≥rios com an√°lise de substitui√ß√µes conclu√≠da")

            return True

        except Exception as e:
            logger.error(f"‚ùå Erro na gera√ß√£o de relat√≥rios: {e}")
            logger.error(traceback.format_exc())
            if self.config.get('pipeline', {}).get('stop_on_failure', False):
                raise
            return False

    def run_complete_pipeline(self, data_path: str = None, output_dir: str = None) -> bool:
        """
        Executa o pipeline completo do sistema de IA COM VALIDA√á√ÉO ESTAT√çSTICA

        Args:
            data_path: Caminho para arquivo de dados
            output_dir: Diret√≥rio de sa√≠da
        """
        try:
            self.start_time = time.time()

            logger.info("\n" + "=" * 80)
            logger.info("üöÄ INICIANDO PIPELINE COMPLETO - SISTEMA IA TUBERCULOSE")
            logger.info("üîÑ COM SUBSTITUI√á√ÉO INTELIGENTE + VALIDA√á√ÉO ESTAT√çSTICA")
            logger.info("=" * 80)

            # Configura o ambiente
            if not self.setup_environment(data_path, output_dir):
                return False

            # NOVA ORDEM: Adiciona valida√ß√£o estat√≠stica
            pipeline_steps = [
                ("üîß Sele√ß√£o de Features com Substitui√ß√£o Inteligente", self.run_feature_selection),
                ("üïê An√°lise Temporal das Features Derivadas", self.run_clinical_timeline_analysis),
                ("üö® Detec√ß√£o de Data Leakage com Features Derivadas", self.run_leakage_detection),
                ("ü§ñ Treinamento Otimizado para Features Derivadas", self.run_model_training),
                ("üß™ Valida√ß√£o Estat√≠stica e Testes de Hip√≥tese", self.run_statistical_validation),  # NOVO
                ("üìÑ Gera√ß√£o de Relat√≥rios com An√°lise Completa", self.run_report_generation)
            ]

            for step_name, step_function in pipeline_steps:
                logger.info(f"\n‚ñ∂Ô∏è Executando: {step_name}")

                step_start = time.time()
                success = step_function()
                step_time = time.time() - step_start

                if success:
                    logger.info(f"‚úÖ {step_name} conclu√≠da em {step_time:.2f}s")
                else:
                    logger.error(f"‚ùå Falha em: {step_name}")

                    # Verifica se deve continuar
                    if self.config.get('pipeline', {}).get('stop_on_failure', False):
                        return False
                    else:
                        logger.warning("‚ö†Ô∏è Continuando pipeline apesar da falha...")

            total_time = time.time() - self.start_time

            # Relat√≥rio final
            self._print_pipeline_summary(total_time)

            # Notifica√ß√µes
            self._send_notifications(success=True)

            return True

        except Exception as e:
            logger.error(f"‚ùå Erro no pipeline: {e}")
            logger.error(traceback.format_exc())

            # Notifica√ß√µes de erro
            self._send_notifications(success=False, error=str(e))

            return False

    def _print_pipeline_summary(self, total_time: float):
        """Imprime resumo final do pipeline COM SUBSTITUI√á√ïES"""
        logger.info("\n" + "=" * 80)
        logger.info("üéâ PIPELINE CONCLU√çDO!")
        logger.info("=" * 80)

        logger.info(f"‚è±Ô∏è Tempo total: {total_time:.2f}s ({total_time / 60:.1f}min)")
        logger.info(f"üìÅ Resultados salvos em: {self.output_dir}")

        # Status das etapas
        logger.info("\nüìã STATUS DAS ETAPAS:")
        status_map = {
            'feature_selection': 'üîß Sele√ß√£o de Features com Substitui√ß√£o',
            'clinical_analysis': 'üïê An√°lise Temporal com Derivadas',
            'leakage_detection': 'üö® Detec√ß√£o de Data Leakage',
            'model_training': 'ü§ñ Treinamento Otimizado',
            'statistical_validation': 'üß™ Valida√ß√£o Estat√≠stica',
            'report_generation': 'üìÑ Gera√ß√£o de Relat√≥rios'
        }

        for key, name in status_map.items():
            status = "‚úÖ CONCLU√çDA" if self.pipeline_status[key] else "‚ùå FALHOU"
            step_time = self.step_times.get(key, 0)
            logger.info(f"   {name}: {status} ({step_time:.1f}s)")

        # Resumo da sele√ß√£o de features COM SUBSTITUI√á√ïES
        if 'feature_selection' in self.results and self.feature_selector:
            processed_scenarios = self.feature_selector.list_processed_scenarios()
            logger.info(f"\nüîß RESUMO DA SELE√á√ÉO DE FEATURES COM SUBSTITUI√á√ïES:")
            logger.info(f"   Cen√°rios processados: {len(processed_scenarios)}")
            logger.info(f"   Features derivadas criadas: {len(self.feature_selector.derived_features)}")
            logger.info(f"   Features originais substitu√≠das: {len(self.feature_selector.replaced_features)}")

            # Resumo de efetividade das substitui√ß√µes
            total_derived_used = 0
            total_replaced_still_used = 0

            for scenario in processed_scenarios:
                data, features = self.feature_selector.get_data_for_scenario(scenario)
                derived_count = len([f for f in features if f in self.feature_selector.derived_features])
                replaced_count = len([f for f in features if f in self.feature_selector.replaced_features])

                total_derived_used += derived_count
                total_replaced_still_used += replaced_count

                logger.info(f"   üéØ {scenario}: {len(features)} features ({derived_count} derivadas), {len(data)} registros")
                if replaced_count > 0:
                    logger.warning(f"      ‚ö†Ô∏è {replaced_count} features substitu√≠das ainda em uso")
                else:
                    logger.info(f"      ‚úÖ Substitui√ß√µes efetivas")

            # An√°lise geral de efetividade
            if total_replaced_still_used == 0:
                logger.info(f"   ‚úÖ SUBSTITUI√á√ïES 100% EFETIVAS - features originais n√£o est√£o sendo usadas")
            else:
                logger.warning(f"   ‚ö†Ô∏è {total_replaced_still_used} features substitu√≠das ainda em uso - revisar configura√ß√£o")

        # Resumo da an√°lise temporal
        if 'clinical_analysis' in self.results:
            clinical_data = self.results['clinical_analysis']
            if 'selected_features_analysis' in clinical_data:
                logger.info(f"\nüïê RESUMO DA AN√ÅLISE TEMPORAL:")
                for scenario, analysis in clinical_data['selected_features_analysis'].items():
                    safe_count = len(analysis['safe_features'])
                    total_count = analysis['total_features']
                    derived_count = len(analysis.get('derived_features_used', []))
                    logger.info(f"   üéØ {scenario}: {safe_count}/{total_count} features seguras ({derived_count} derivadas)")

        # Resumo da detec√ß√£o de leakage
        if 'leakage_detection' in self.results:
            leakage_data = self.results['leakage_detection']
            overall_risk = leakage_data.get('overall_risk_level', 'UNKNOWN')
            logger.info(f"\nüö® RESUMO DA DETEC√á√ÉO DE LEAKAGE:")
            logger.info(f"   Risco geral: {overall_risk}")
            logger.info(f"   üîÑ Features derivadas tratadas como seguras")

            if 'results_by_scenario' in leakage_data:
                for scenario, results in leakage_data['results_by_scenario'].items():
                    suspicious_count = results['suspicious_count']
                    total_count = results['total_features']
                    derived_safe = results.get('derived_features_safe', 0)
                    logger.info(f"   üéØ {scenario}: {suspicious_count}/{total_count} features suspeitas (originais), {derived_safe} derivadas seguras")

        if 'statistical_validation' in self.results:
            validation_data = self.results['statistical_validation']
            overall_assessment = validation_data.get('overall_assessment', {})

            logger.info(f"\nüß™ RESUMO DA VALIDA√á√ÉO ESTAT√çSTICA:")
            logger.info(f"   Status: {overall_assessment.get('overall_status', 'N/A')}")
            logger.info(f"   Taxa de signific√¢ncia: {overall_assessment.get('significance_rate', 0):.1%}")
            logger.info(f"   Recomenda√ß√£o: {overall_assessment.get('recommendation', 'N/A')}")

            # Mostrar testes individuais
            for assessment in overall_assessment.get('test_assessments', []):
                status_icon = "‚úÖ" if assessment['significant'] else "‚ö†Ô∏è"
                logger.info(f"      {status_icon} {assessment['test']}")

        # Resultados do modelo por cen√°rio
        if 'model_training' in self.results:
            training_data = self.results['model_training']

            # Verificar estrutura correta
            if 'scenarios' in training_data:
                logger.info(f"\nüèÜ RESULTADOS DOS MODELOS POR CEN√ÅRIO:")

                best_scenario = None
                best_score = 0

                for scenario, result in training_data['scenarios'].items():
                    # Acessar m√©tricas corretamente
                    if 'predictor' in result and hasattr(result['predictor'], 'results'):
                        metrics = result['predictor'].results
                        acc = metrics.get('balanced_accuracy', 0)
                        f1 = metrics.get('f1_score', 0)
                        auc = metrics.get('auc_score', 0)
                        meta_model = result.get('best_meta_name', 'N/A')
                        derived_used = result.get('derived_features_used', [])

                        logger.info(f"   üéØ {scenario}:")
                        logger.info(f"      üìä Acur√°cia: {acc:.3f}")
                        logger.info(f"      üéØ F1-Score: {f1:.3f}")
                        logger.info(f"      üìà AUC: {auc:.3f}")
                        logger.info(f"      üèÖ Meta-modelo: {meta_model}")
                        logger.info(f"      üîÑ Features derivadas: {len(derived_used)}")

                        if acc > best_score:
                            best_score = acc
                            best_scenario = scenario

                if best_scenario:
                    logger.info(f"\nüèÜ MELHOR MODELO: {best_scenario} (Acur√°cia: {best_score:.3f})")

        # Arquivos gerados
        logger.info(f"\nüíæ ARQUIVOS GERADOS:")
        if 'report_generation' in self.results:
            generated_files = self.results['report_generation'].get('generated_files', [])
            for file_path in generated_files[:10]:
                logger.info(f"   üìÑ {Path(file_path).name}")

            if len(generated_files) > 10:
                logger.info(f"   ... e mais {len(generated_files) - 10} arquivos")

        # Lista de relat√≥rios espec√≠ficos
        reports_dir = self.output_dir / "reports"
        if reports_dir.exists():
            logger.info(f"\nüìã RELAT√ìRIOS ESPEC√çFICOS GERADOS:")
            specific_reports = [
                "01_feature_selection_summary.txt",
                "02_clinical_timeline_analysis.txt",
                "02_selected_features_temporal_analysis.txt",
                "03_leakage_detection_report.txt"
            ]

            for report in specific_reports:
                report_path = reports_dir / report
                if report_path.exists():
                    logger.info(f"   üìÑ {report}")

        logger.info(f"\n‚úÖ SISTEMA IA TUBERCULOSE INFANTIL - CONCLU√çDO!")
        logger.info(f"üîÑ SUBSTITUI√á√ÉO INTELIGENTE DE FEATURES APLICADA")
        logger.info(f"üìä Configura√ß√£o usada salva em: {self.output_dir}/logs/config_used.yaml")
        logger.info("=" * 80)

    def save_checkpoint(self, step: str):
        """Salva checkpoint para permitir resumo"""
        try:
            if not self.config.get('pipeline', {}).get('save_checkpoints', True):
                return

            checkpoint_dir = self.output_dir / "checkpoints"
            checkpoint_dir.mkdir(exist_ok=True)

            checkpoint_path = checkpoint_dir / f"{step}.json"

            checkpoint_data = {
                'step': step,
                'timestamp': datetime.now().isoformat(),
                'status': self.pipeline_status,
                'step_times': self.step_times,
                'config_snapshot': self.config,
                'results_keys': list(self.results.keys()),
                'substitution_enabled': self.config.get('feature_selection', {}).get('feature_replacement', {}).get('enable_smart_replacement', True)
            }

            with open(checkpoint_path, 'w', encoding='utf-8') as f:
                json.dump(checkpoint_data, f, indent=2, default=str)

            logger.debug(f"üíæ Checkpoint salvo: {checkpoint_path}")

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao salvar checkpoint: {e}")

    def _send_notifications(self, success: bool, error: str = None):
        """Envia notifica√ß√µes se configuradas"""
        try:
            notifications_config = self.config.get('notifications', {})

            # Prepara mensagem
            if success:
                message = f"‚úÖ Pipeline IA Tuberculose com Substitui√ß√£o Inteligente conclu√≠do com sucesso!\n"
                message += f"üìä Tempo total: {time.time() - self.start_time:.1f}s\n"
                if self.feature_selector:
                    message += f"üîÑ Features derivadas: {len(self.feature_selector.derived_features)}\n"
                    message += f"üîÑ Features substitu√≠das: {len(self.feature_selector.replaced_features)}\n"
                message += f"üìÅ Resultados: {self.output_dir}"
            else:
                message = f"‚ùå Pipeline IA Tuberculose falhou!\n"
                if error:
                    message += f"üî• Erro: {error[:200]}...\n"
                message += f"üìÅ Logs: {self.output_dir}/logs/"

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao enviar notifica√ß√µes: {e}")

    def get_pipeline_status(self) -> Dict[str, Any]:
        """Retorna status detalhado do pipeline COM INFORMA√á√ïES DE SUBSTITUI√á√ÉO"""
        status = {
            'status': self.pipeline_status,
            'step_times': self.step_times,
            'total_time': time.time() - self.start_time if self.start_time else 0,
            'results_summary': {
                key: {
                    'completed': key in self.results,
                    'timestamp': self.results[key].get('timestamp') if key in self.results else None
                } for key in self.pipeline_status.keys()
            },
            'config_summary': {
                'sections': list(self.config.keys()),
                'use_tabpfn': self.config.get('model', {}).get('use_tabpfn', True),
                'max_features': self.config.get('model', {}).get('max_features', 15),
                'cv_folds': self.config.get('model', {}).get('cv_folds', 10),
                'substitution_enabled': self.config.get('feature_selection', {}).get('feature_replacement', {}).get('enable_smart_replacement', True)
            },
            'output_dir': str(self.output_dir) if self.output_dir else None
        }

        # Adiciona informa√ß√µes de substitui√ß√£o se dispon√≠vel
        if self.feature_selector:
            status['substitution_summary'] = {
                'derived_features_created': len(self.feature_selector.derived_features),
                'original_features_replaced': len(self.feature_selector.replaced_features),
                'derived_features_list': self.feature_selector.derived_features,
                'replaced_features_list': list(self.feature_selector.replaced_features),
                'replacement_strategy': self.config.get('feature_selection', {}).get('feature_replacement', {}).get('replacement_strategy', 'unknown')
            }

        return status

    def run_statistical_validation(self) -> bool:
        """
        ETAPA 5: Valida√ß√£o Estat√≠stica e Testes de Hip√≥tese
        Executa bateria completa de testes estat√≠sticos para valida√ß√£o m√©dica
        """
        try:
            step_start = time.time()
            logger.info("\n" + "=" * 70)
            logger.info("üß™ ETAPA 5: VALIDA√á√ÉO ESTAT√çSTICA E TESTES DE HIP√ìTESE")
            logger.info("=" * 70)

            # Verificar se m√≥dulo est√° dispon√≠vel
            if not STATISTICAL_VALIDATION_AVAILABLE:
                logger.error("‚ùå M√≥dulo de valida√ß√£o estat√≠stica n√£o dispon√≠vel!")
                return False

            if 'model_training' not in self.results:
                logger.error("‚ùå Treinamento de modelos n√£o executado!")
                return False

            logger.info("üß™ Executando bateria completa de testes de hip√≥tese m√©dicos...")

            # Configura√ß√µes da valida√ß√£o estat√≠stica
            validation_config = self.config.get('statistical_validation', {
                'confidence_level': 0.95,
                'non_inferiority_margin': 0.05,
                'baseline_performance': 0.70
            })

            # Chama a fun√ß√£o importada do m√≥dulo de valida√ß√£o
            validation_results = statistical_validation_func(
                training_results=self.results['model_training'],
                feature_selector=self.feature_selector,
                output_dir=self.output_dir,
                config=self.config
            )

            if validation_results.get('status') == 'ERROR':
                logger.error(f"‚ùå Erro na valida√ß√£o estat√≠stica: {validation_results.get('error')}")
                return False

            # Armazenar resultados
            self.results['statistical_validation'] = {
                'validation_results': validation_results['validation_results'],
                'overall_assessment': validation_results['overall_assessment'],
                'report_path': validation_results['report_path'],
                'config_used': validation_results['config_used'],
                'timestamp': datetime.now()
            }

            self.pipeline_status['statistical_validation'] = True
            self.step_times['statistical_validation'] = time.time() - step_start

            # An√°lise dos resultados
            overall_assessment = validation_results['overall_assessment']
            overall_status = overall_assessment['overall_status']
            significance_rate = overall_assessment['significance_rate']

            logger.info(f"\nüìä RESULTADOS DA VALIDA√á√ÉO ESTAT√çSTICA:")
            logger.info(f"   Status geral: {overall_status}")
            logger.info(f"   Taxa de signific√¢ncia: {significance_rate:.1%}")
            logger.info(
                f"   Testes significativos: {overall_assessment['significant_tests']}/{overall_assessment['total_tests']}")
            logger.info(f"   Recomenda√ß√£o: {overall_assessment['recommendation']}")

            # Log dos testes individuais
            for assessment in overall_assessment['test_assessments']:
                status_icon = "‚úÖ" if assessment['significant'] else "‚ö†Ô∏è"
                logger.info(
                    f"   {status_icon} {assessment['test']}: {'Significativo' if assessment['significant'] else 'N√£o significativo'}")

            # Verificar se sistema foi aprovado
            if overall_status == 'APROVADO':
                logger.info("üéâ SISTEMA VALIDADO ESTATISTICAMENTE PARA USO CL√çNICO!")
            elif overall_status == 'APROVADO_COM_RESSALVAS':
                logger.warning("‚ö†Ô∏è SISTEMA APROVADO COM RESSALVAS - Monitoramento adicional necess√°rio")
            else:
                logger.error("‚ùå SISTEMA REPROVADO NA VALIDA√á√ÉO ESTAT√çSTICA")

                # Configura√ß√£o para parar ou continuar
                stop_on_statistical_failure = self.config.get('pipeline', {}).get('stop_on_statistical_failure', False)
                if stop_on_statistical_failure:
                    logger.error("üõë Pipeline interrompido devido √† reprova√ß√£o estat√≠stica")
                    return False
                else:
                    logger.warning("‚ö†Ô∏è Continuando pipeline apesar da reprova√ß√£o (configura√ß√£o)")

            # Checkpoint
            if self.config.get('pipeline', {}).get('save_checkpoints', True):
                self.save_checkpoint('statistical_validation')

            logger.info("‚úÖ Valida√ß√£o estat√≠stica conclu√≠da")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erro na valida√ß√£o estat√≠stica: {e}")
            logger.error(traceback.format_exc())
            if self.config.get('pipeline', {}).get('stop_on_failure', False):
                raise
            return False


def main():
    """Fun√ß√£o principal para executar o sistema completo COM SUBSTITUI√á√ÉO INTELIGENTE"""

    try:
        # Configura√ß√£o padr√£o (ser√° sobrescrita por args/config)
        DATA_PATH = None
        OUTPUT_DIR = None

        # Inicializa sistema com configura√ß√£o
        ai_system = TuberculosisAISystem()

        # Executa pipeline completo
        success = ai_system.run_complete_pipeline(
            data_path=DATA_PATH,
            output_dir=OUTPUT_DIR
        )

        if success:
            logger.info("üéâ Sistema executado com sucesso!")

            # Mostra status final COM INFORMA√á√ïES DE SUBSTITUI√á√ÉO
            status = ai_system.get_pipeline_status()
            logger.info("üìä Status final do pipeline:")
            for step, completed in status['status'].items():
                time_taken = status['step_times'].get(step, 0)
                logger.info(f"   {step}: {'‚úÖ' if completed else '‚ùå'} ({time_taken:.1f}s)")

            # Mostra resumo das substitui√ß√µes
            if 'substitution_summary' in status:
                subst = status['substitution_summary']
                logger.info(f"\nüîÑ RESUMO DAS SUBSTITUI√á√ïES:")
                logger.info(f"   Features derivadas criadas: {subst['derived_features_created']}")
                logger.info(f"   Features originais substitu√≠das: {subst['original_features_replaced']}")
                logger.info(f"   Estrat√©gia utilizada: {subst['replacement_strategy']}")

            return 0
        else:
            logger.error("‚ùå Falha na execu√ß√£o do sistema")
            return 1

    except KeyboardInterrupt:
        logger.warning("‚ö†Ô∏è Execu√ß√£o interrompida pelo usu√°rio")
        return 130

    except Exception as e:
        logger.error(f"‚ùå Erro cr√≠tico: {e}")
        logger.error(traceback.format_exc())
        return 1


if __name__ == "__main__":
    exit(main())